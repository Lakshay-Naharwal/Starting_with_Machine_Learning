





import pandas as pd





!pip install mysql.connector
!pip install sqlalchemy






import mysql.connector 





conn = mysql.connector.connect(
    host='localhost',
    user='root',
    password='',
    database='world'
)






pd.read_sql_query("SELECT * FROM city WHERE CountryCode LIKE 'USA'", conn)











import requests

url = "https://anime-db.p.rapidapi.com/anime"

querystring = {"page":"1","size":"10","search":"Fullmetal","genres":"Fantasy,Drama","sortBy":"ranking","sortOrder":"asc"}

headers = {
	"x-rapidapi-key": "5eadd6bc7emsh83392246ef39d66p14ffd4jsn9887126a5414",
	"x-rapidapi-host": "anime-db.p.rapidapi.com"
}

response = requests.get(url, headers=headers, params=querystring)

df=pd.DataFrame(response.json()['data'])


print(df.shape)








import pandas as pd
import requests as re
from bs4 import BeautifulSoup
!pip install lxml
import lxml





headers={'User-Agent':'Mozilla/5.0 (Windows NT 6.3; Win 64 ; x64) Apple WeKit /537.36(KHTML , like Gecko) Chrome/80.0.3987.162 Safari/537.36'}





webpage =requests.get('https://www.ambitionbox.com/list-of-companies?page=1',headers=headers).text





soup = BeautifulSoup(webpage , 'lxml')





company = soup.find_all('div', class_='companyCardWrapper')
len(company)





names=[]
rating=[]
No_Of_Reviews=[]
ctype=[]
locations=[]
company_type=''
location=''

for i in company:
    names.append(i.find('h2').text.strip())
    rating.append(i.find('div', class_='rating_star_container').text.strip())
    No_Of_Reviews.append(i.find('span' , class_='companyCardWrapper__companyRatingCount').text.strip())
    misc_info = i.find('span', class_='companyCardWrapper__interLinking')
    if misc_info:
    # Split by "|" to separate type and location
        parts = misc_info.text.split('|')
        
        # Company Type (first part)
        company_type = parts[0].strip() if len(parts) > 0 else ''
        ctype.append(company_type)
        
        # Location (second part)
        location = parts[1].strip() if len(parts) > 1 else ''
        locations.append(location)
    else:
        ctype.append('')
        locations.append('')
    


names


rating


No_Of_Reviews


ctype


locations





df = pd.DataFrame({
    'Company_Name': names,
    'Rating': rating,
    'No_Of_Reviews': No_Of_Reviews,
    'Company_Type': ctype,
    'Location': locations
})



df





import pandas as pd
import requests 
from bs4 import BeautifulSoup



final = pd.DataFrame()

for j in range (1,501):
    url='https://www.ambitionbox.com/list-of-companies?page={}'.format(j)
    headers={'User-Agent':'Mozilla/5.0 (Windows NT 6.3; Win 64 ; x64) Apple WeKit /537.36(KHTML , like Gecko) Chrome/80.0.3987.162 Safari/537.36'}
    webpage =requests.get(url,headers=headers).text
    soup = BeautifulSoup(webpage , 'lxml')
    company = soup.find_all('div', class_='companyCardWrapper')
   
    names=[]
    rating=[]
    No_Of_Reviews=[]
    ctype=[]
    locations=[]
    company_type=''
    location=''
    for i in company:

        names.append(i.find('h2').text.strip())
        rating.append(i.find('div', class_='rating_star_container').text.strip())
        No_Of_Reviews.append(i.find('span' , class_='companyCardWrapper__companyRatingCount').text.strip())
        misc_info = i.find('span', class_='companyCardWrapper__interLinking')
        if misc_info:
        # Split by "|" to separate type and location
            parts = misc_info.text.split('|')
            
            # Company Type (first part)
            company_type = parts[0].strip() if len(parts) > 0 else ''
            ctype.append(company_type)
            
            # Location (second part)
            location = parts[1].strip() if len(parts) > 1 else ''
            locations.append(location)
        else:
            ctype.append('')
            locations.append('')

    df = pd.DataFrame({
        'Company_Name': names,
        'Rating': rating,
        'No_Of_Reviews': No_Of_Reviews,
        'Company_Type': ctype,
        'Location': locations
    })

    final = pd.concat([final, df], ignore_index=True)

                    
            
    



final



df





final.to_csv('ambitionbox_companies1.csv')



